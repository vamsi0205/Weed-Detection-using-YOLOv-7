# -*- coding: utf-8 -*-
"""Preprocessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KgNGpA4kOLB5NcBh0qFebDEPc7MAIPbl
"""

from google.colab import drive
drive.mount('/content/drive')

"""# **Loading The Dataset**"""

import os

dataset_path1 = '/content/gdrive/MyDrive/fourweed_dataset/cocklebur'

dataset_path2 = '/content/gdrive/MyDrive/fourweed_dataset/foxtail'

dataset_path3 = '/content/gdrive/MyDrive/fourweed_dataset/pigweed'

dataset_path4 = '/content/gdrive/MyDrive/fourweed_dataset/ragweed'

"""# **Data Augmentation**"""

import albumentations as A
import cv2
def agument(aug,image):
    augmented = aug(image=image)
    return augmented['image']
def horizontalFlip(image):
    aug = A.HorizontalFlip(p=1)
    return agument(aug,image)
def verticalFlip(image):
    aug = A.VerticalFlip(p=1)
    return agument(aug,image)
def transpose(image):
    aug = A.Transpose(p=1)
    return agument(aug,image)
def randomBrightnessContrast(image):
    aug = A.RandomBrightnessContrast(p=1,brightness_limit=0.5, contrast_limit=0.4)
    return agument(aug,image)


# Path to the dataset folder
dataset_path = dataset_path1

# List all image files in the dataset folder
image_files = [f for f in os.listdir(dataset_path)]

# Apply augmentations to each image in the dataset
for image_file in image_files:
    # Load the image
    image_path = os.path.join(dataset_path, image_file)
    image = cv2.imread(image_path)

    # Apply augmentations
    augmented_image_hf = horizontalFlip(image)
    augmented_image_vf = verticalFlip(image)
    augmented_image_tp = transpose(image)
    augmented_image_bc = randomBrightnessContrast(image)

    # Save the augmented images
    cv2.imwrite(os.path.join(dataset_path, 'augmented_hf_' + image_file), augmented_image_hf)
    cv2.imwrite(os.path.join(dataset_path, 'augmented_vf_' + image_file), augmented_image_vf)
    cv2.imwrite(os.path.join(dataset_path, 'augmented_tp_' + image_file), augmented_image_tp)
    cv2.imwrite(os.path.join(dataset_path, 'augmented_bc_' + image_file), augmented_image_bc)

# Path to the dataset folder
dataset_path = dataset_path2

# List all image files in the dataset folder
image_files = [f for f in os.listdir(dataset_path)]

# Apply augmentations to each image in the dataset
for image_file in image_files:
    # Load the image
    image_path = os.path.join(dataset_path, image_file)
    image = cv2.imread(image_path)

    # Apply augmentations
    augmented_image_hf = horizontalFlip(image)
    augmented_image_vf = verticalFlip(image)
    augmented_image_tp = transpose(image)
    augmented_image_bc = randomBrightnessContrast(image)

    # Save the augmented images
    cv2.imwrite(os.path.join(dataset_path, 'augmented_hf_' + image_file), augmented_image_hf)
    cv2.imwrite(os.path.join(dataset_path, 'augmented_vf_' + image_file), augmented_image_vf)
    cv2.imwrite(os.path.join(dataset_path, 'augmented_tp_' + image_file), augmented_image_tp)
    cv2.imwrite(os.path.join(dataset_path, 'augmented_bc_' + image_file), augmented_image_bc)

# Path to the dataset folder
dataset_path = dataset_path3

# List all image files in the dataset folder
image_files = [f for f in os.listdir(dataset_path)]

# Apply augmentations to each image in the dataset
for image_file in image_files:
    # Load the image
    image_path = os.path.join(dataset_path, image_file)
    image = cv2.imread(image_path)

    # Apply augmentations
    augmented_image_hf = horizontalFlip(image)
    augmented_image_vf = verticalFlip(image)
    augmented_image_tp = transpose(image)
    augmented_image_bc = randomBrightnessContrast(image)

    # Save the augmented images
    cv2.imwrite(os.path.join(dataset_path, 'augmented_hf_' + image_file), augmented_image_hf)
    cv2.imwrite(os.path.join(dataset_path, 'augmented_vf_' + image_file), augmented_image_vf)
    cv2.imwrite(os.path.join(dataset_path, 'augmented_tp_' + image_file), augmented_image_tp)
    cv2.imwrite(os.path.join(dataset_path, 'augmented_bc_' + image_file), augmented_image_bc)

# Path to the dataset folder
dataset_path = dataset_path4

# List all image files in the dataset folder
image_files = [f for f in os.listdir(dataset_path)]

# Apply augmentations to each image in the dataset
for image_file in image_files:
    # Load the image
    image_path = os.path.join(dataset_path, image_file)
    image = cv2.imread(image_path)

    # Apply augmentations
    augmented_image_hf = horizontalFlip(image)
    augmented_image_vf = verticalFlip(image)
    augmented_image_tp = transpose(image)
    augmented_image_bc = randomBrightnessContrast(image)

    # Save the augmented images
    cv2.imwrite(os.path.join(dataset_path, 'augmented_hf_' + image_file), augmented_image_hf)
    cv2.imwrite(os.path.join(dataset_path, 'augmented_vf_' + image_file), augmented_image_vf)
    cv2.imwrite(os.path.join(dataset_path, 'augmented_tp_' + image_file), augmented_image_tp)
    cv2.imwrite(os.path.join(dataset_path, 'augmented_bc_' + image_file), augmented_image_bc)

dest_path = "/content/gdrive/MyDrive/"+"preprocessed/"
os.makedirs(dest_path, exist_ok=True)

"""# **Resizing the Images**"""

def resize(image): #While agumenting the data we are converting all images into the size of (640,640)
    aug = A.Resize(height=640,width=640,p=1)
    return agument(aug,image)

dataset_path = dataset_path1

# List all image files in the dataset folder
image_files = [f for f in os.listdir(dataset_path)]

# Apply augmentations to each image in the dataset
for image_file in image_files:
    # Load the image
    image_path = os.path.join(dataset_path, image_file)
    image = cv2.imread(image_path)

    # Apply augmentations
    resized_image = resize(image)

    # Save the augmented images
    cv2.imwrite(os.path.join(dest_path + image_file), resized_image)

dataset_path = dataset_path2

# List all image files in the dataset folder
image_files = [f for f in os.listdir(dataset_path)]

# Apply augmentations to each image in the dataset
for image_file in image_files:
    # Load the image
    image_path = os.path.join(dataset_path, image_file)
    image = cv2.imread(image_path)

    # Apply augmentations
    resized_image = resize(image)

    # Save the augmented images
    cv2.imwrite(os.path.join(dest_path + image_file), resized_image)

dataset_path = dataset_path3

# List all image files in the dataset folder
image_files = [f for f in os.listdir(dataset_path)]

# Apply augmentations to each image in the dataset
for image_file in image_files:
    # Load the image
    image_path = os.path.join(dataset_path, image_file)
    image = cv2.imread(image_path)

    # Apply augmentations
    resized_image = resize(image)

    # Save the augmented images
    cv2.imwrite(os.path.join(dest_path + image_file), resized_image)

dataset_path = dataset_path4

# List all image files in the dataset folder
image_files = [f for f in os.listdir(dataset_path)]

# Apply augmentations to each image in the dataset
for image_file in image_files:
    # Load the image
    image_path = os.path.join(dataset_path, image_file)
    image = cv2.imread(image_path)

    # Apply augmentations
    resized_image = resize(image)

    # Save the augmented images
    cv2.imwrite(os.path.join(dest_path + image_file), resized_image)

"""# **Splitting data into Training and Testing Sets**"""

import os
import random
import shutil

def split_dataset(image_dir, annotation_dir, train_ratio=0.6, test_ratio=0.2, valid_ratio=0.2):
    image_files = [file for file in os.listdir(image_dir) if file.endswith('.jpg') or file.endswith('.png')]
    total_images = len(image_files)
    random.shuffle(image_files)

    train_split = int(total_images * train_ratio)
    test_split = int(total_images * (train_ratio + test_ratio))

    train_files = image_files[:train_split]
    test_files = image_files[train_split:test_split]
    valid_files = image_files[test_split:]

    def create_split_directories(split_dir):
        os.makedirs(os.path.join(split_dir, "images"), exist_ok=True)
        os.makedirs(os.path.join(split_dir, "annotations"), exist_ok=True)

    create_split_directories("/content/drive/MyDrive/train")
    create_split_directories("/content/drive/MyDrive/test")
    create_split_directories("/content/drive/MyDrive/valid")

    def move_files(file_list, source_image_dir, source_annotation_dir, target_dir):
        for filename in file_list:
            img_path = os.path.join(source_image_dir, filename)
            ann_filename = filename.replace('.jpg', '.txt').replace('.png', '.txt')
            ann_path = os.path.join(source_annotation_dir, ann_filename)

            target_img_path = os.path.join(target_dir, "images", filename)
            target_ann_path = os.path.join(target_dir, "annotations", ann_filename)

            shutil.copy(img_path, target_img_path)
            shutil.copy(ann_path, target_ann_path)

    move_files(train_files, image_dir, annotation_dir, "/content/drive/MyDrive/train")
    move_files(test_files, image_dir, annotation_dir, "/content/drive/MyDrive/test")
    move_files(valid_files, image_dir, annotation_dir, "/content/drive/MyDrive/valid")

# Replace these paths with the directories containing your image and annotation files
image_dir = "/content/drive/MyDrive/Project_Dataset/Images"
annotation_dir = "/content/drive/MyDrive/Project_Dataset/Annotations"

split_dataset(image_dir, annotation_dir)